{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590e868b-dbe8-4156-bced-a0c1afe3357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   numeric_covariate categorical_variable  target\n",
      "0          10.993428                    C       0\n",
      "1           9.723471                    C       1\n",
      "2          11.295377                    B       1\n",
      "3          13.046060                    C       1\n",
      "4           9.531693                    C       1 (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Numeric covariate with missing values\n",
    "n_samples = 1000\n",
    "numeric_covariate = np.random.normal(loc=10, scale=2, size=n_samples)\n",
    "missing_indices = np.random.choice(range(n_samples), size=int(0.1 * n_samples), replace=False)\n",
    "numeric_covariate[missing_indices] = np.nan\n",
    "\n",
    "# Categorical variable\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "categorical_variable = np.random.choice(categories, size=n_samples)\n",
    "\n",
    "# Binary target (outcome)\n",
    "target = np.random.randint(0, 2, size=n_samples)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'numeric_covariate': numeric_covariate,\n",
    "    'categorical_variable': categorical_variable,\n",
    "    'target': target\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head(), df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33fc7ae-0d8c-49de-a3a6-e22bb78bffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.4800\n",
      "Best hyperparameters: {'classifier__C': 0.1, 'classifier__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset (replace with your actual data)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Assume 'numeric_covariate' and 'categorical_variable' are column names\n",
    "numeric_features = ['numeric_covariate']\n",
    "categorical_features = ['categorical_variable']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['target']), df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))  # Impute missing values with mean\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical variables\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with SVC and RandomForestClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC())  # You can replace with RandomForestClassifier()\n",
    "])\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best model accuracy: {accuracy:.4f}\")\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7842f09-0cc7-4146-a2b9-24ddf3a584ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 123)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:123\u001b[1;36m\u001b[0m\n\u001b[1;33m    )\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/brijlaldhankour/flood-prediction-factors\n",
    "# https://www.kaggle.com/competitions/playground-series-s4e5\n",
    "import sklearn\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import Perceptron, LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, make_scorer, mean_squared_error, r2_score, mean_absolute_percentage_error, max_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Assume 'numeric_covariate' and 'categorical_variable' are column names\n",
    "numeric_features     = ['numeric_covariate1',    'numeric_covariate2'   ]\n",
    "categorical_features = ['categorical_variable1', 'categorical_variable2']\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'SVM'             : SVR(cache_size = 2000),\n",
    "    #'LinearRegression': LinearRegression(),\n",
    "    'LASSO'           : Lasso(),\n",
    "    #'Ridge'           : Ridge(),\n",
    "    'RandomForest'    : RandomForestRegressor(),\n",
    "    'GradientBoost'   : GradientBoostingRegressor(),\n",
    "    'Dummy'           : DummyRegressor()\n",
    "}\n",
    "\n",
    "# Define the preprocessors\n",
    "preprocessors = {\n",
    "    'None': None,\n",
    "    'pp1': ColumnTransformer(\n",
    "        [\n",
    "            ('numeric_cols', numeric_transformer,                    numeric_features),\n",
    "            ('categor_cols', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder = 'passthrough',\n",
    "        n_jobs = 10\n",
    "    )\n",
    "}\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "\n",
    "    'SVM': [\n",
    "        {\n",
    "            'model__C': [0.1, 1, 100],\n",
    "            'model__epsilon': [0.01, 0.1, 0.2]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'LinearRegression': [\n",
    "        {\n",
    "            'model__fit_intercept': [True]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'LASSO': [\n",
    "        {\n",
    "            'model__fit_intercept': [True],\n",
    "            'model__alpha': [0.1, 1, 10, 100]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'Ridge': [\n",
    "        {\n",
    "            'model__fit_intercept': [True],\n",
    "            'model__alpha': [0.1, 1, 10, 100]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'RandomForest': [\n",
    "        {\n",
    "            'model__n_estimators': [10, 100, 500],\n",
    "            'model__max_depth': [None, 2]\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'GradientBoost': [\n",
    "        {\n",
    "            'model__n_estimators': [10, 100, 500],\n",
    "            'model__learning_rate': [0.1, 0.2]\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    'Dummy': [\n",
    "        {\n",
    "            'model__strategy': ['mean', 'median']\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'model__strategy': ['constant'], \n",
    "            'model__constant': [0, 0.5, 1]\n",
    "        },\n",
    "\n",
    "        {\n",
    "            'model__strategy': ['quantile'],\n",
    "            'model__quantile': [0, 0.5, 1]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "scorer = r2_score\n",
    "\n",
    "best_score = 0\n",
    "best_model = None\n",
    "for model_name, model in models.items():\n",
    "    for preprocessor_name, preprocessor in preprocessors.items():\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('model',  model)\n",
    "            ]\n",
    "        )\n",
    "        print(\n",
    "            f'preprocessor: {preprocessor_name}'\n",
    "            f'\\n'\n",
    "            f'Model: {model_name}'\n",
    "        )\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator  = pipeline,\n",
    "            param_grid = param_grids[model_name],\n",
    "            cv = 10, \n",
    "            scoring = make_scorer(scorer),\n",
    "            refit = True,\n",
    "            n_jobs = -1,\n",
    "            verbose = 4\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model on the train set\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        test_score = scorer(y_test, y_pred)\n",
    "\n",
    "        # Print results of grid parameter search\n",
    "        print(f\"Best parameters for {model_name} with {preprocessor_name}: {grid_search.best_params_}\")\n",
    "        print(f\"Train set score for {model_name} with {preprocessor_name}: {grid_search.best_score_:.4f}\")\n",
    "        print( f\"Test set score for {model_name} with {preprocessor_name}: {test_score:.4f}\\n\")\n",
    "        \n",
    "        # Update best model if necessary\n",
    "        if test_score > best_score:\n",
    "            best_score = test_score\n",
    "            best_model = model_name\n",
    "            best_estimator = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best performing model: {best_model}\")\n",
    "print(f\"Best Model's Score on the test set: {best_score:.4f}\")\n",
    "print(f\"Scorer was: {scorer.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3e857-7fb6-4fca-a7fa-682fe74adc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
